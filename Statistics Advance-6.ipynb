{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb4a90af",
   "metadata": {},
   "source": [
    "## Assignment: Statistics Advance-6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3612bf6",
   "metadata": {},
   "source": [
    "### Q1. Explain the assumptions required to use ANOVA and provide examples of violations that could impact the validity of the results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c39a897c",
   "metadata": {},
   "source": [
    "**Ans:** ANOVA (Analysis of Variance) is a statistical technique used to analyze the differences between means of two or more groups. The assumptions required for using ANOVA are:\n",
    "\n",
    "Independence of observations: The observations in each group should be independent of each other, and there should be no relationship between the observations in different groups.\n",
    "\n",
    "Normality: The distribution of the residuals (the differences between the observed values and the predicted values) for each group should be normal.\n",
    "\n",
    "Homogeneity of variance: The variances of the residuals should be equal across all groups.\n",
    "\n",
    "Examples of violations that could impact the validity of ANOVA results include:\n",
    "\n",
    "Violation of independence: This occurs when the observations within each group are not independent. For example, if a study compares the test scores of siblings in a family, the scores of siblings are not independent, and ANOVA cannot be used.\n",
    "\n",
    "Violation of normality: If the residuals are not normally distributed within each group, then ANOVA results can be biased. For example, if the residuals are skewed or have extreme outliers, ANOVA may not be appropriate.\n",
    "\n",
    "Violation of homogeneity of variance: If the variances of the residuals are not equal across all groups, then ANOVA results can be affected. For example, if the variance of the residuals in one group is much larger than the others, this can lead to an incorrect conclusion.\n",
    "\n",
    "In summary, violating the assumptions of ANOVA can impact the validity of the results and lead to incorrect conclusions. Therefore, it is important to check for these assumptions before applying ANOVA and consider alternative methods if the assumptions are not met."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dc79173",
   "metadata": {},
   "source": [
    "### Q2. What are the three types of ANOVA, and in what situations would each be used?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35decbb6",
   "metadata": {},
   "source": [
    "**Ans:** The three types of ANOVA are:\n",
    "\n",
    "- One-Way ANOVA: This type of ANOVA is used when there is only one independent variable and one dependent variable. It is used to test for differences between two or more groups. For example, if we want to compare the average scores of three different schools on a standardized test, we can use One-Way ANOVA.\n",
    "\n",
    "- Two-Way ANOVA: This type of ANOVA is used when there are two independent variables and one dependent variable. It is used to test for the main effects of each independent variable and their interaction. For example, if we want to compare the effect of two different diets and two different exercise routines on weight loss, we can use Two-Way ANOVA.\n",
    "\n",
    "- Mixed ANOVA: This type of ANOVA is used when there are two or more independent variables, and at least one of them is a between-subjects factor, and at least one of them is a within-subjects factor. A within-subjects factor is a variable where each participant is measured multiple times under different conditions. A between-subjects factor is a variable where different participants are assigned to different conditions. For example, if we want to compare the effect of two different types of cognitive training (between-subjects factor) and two different time points (within-subjects factor) on memory performance, we can use Mixed ANOVA."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f14f0ff",
   "metadata": {},
   "source": [
    "### Q3. What is the partitioning of variance in ANOVA, and why is it important to understand this concept?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61964d55",
   "metadata": {},
   "source": [
    "**Ans:** The partitioning of variance is a key concept in ANOVA that refers to the division of the total variation in the data into different sources of variation. The total variance is then partitioned into two components: the variation between groups and the variation within groups.\n",
    "\n",
    "The variation between groups represents the differences between the means of each group, and it is the source of interest in ANOVA. The variation within groups represents the differences within each group, which can be due to measurement error, individual differences, or other sources of variation.\n",
    "\n",
    "Understanding the partitioning of variance is important for several reasons:\n",
    "\n",
    "It allows us to determine whether there are significant differences between the means of different groups. If the variation between groups is significantly larger than the variation within groups, then we can conclude that there are significant differences between the means of the groups.\n",
    "\n",
    "It helps us to identify the sources of variation that are contributing to the overall variability in the data. By identifying the sources of variation, we can design better experiments and improve our understanding of the underlying processes.\n",
    "\n",
    "It allows us to estimate the effect size of the differences between the groups. By comparing the variation between groups to the variation within groups, we can compute an effect size, which is a measure of the strength of the differences between the groups.\n",
    "\n",
    "In summary, understanding the partitioning of variance is crucial for interpreting the results of ANOVA and for making valid conclusions about the differences between groups. It allows us to determine whether the differences between groups are significant, identify the sources of variation, and estimate the effect size of the differences."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfea650f",
   "metadata": {},
   "source": [
    "### Q4. How would you calculate the total sum of squares (SST), explained sum of squares (SSE), and residual sum of squares (SSR) in a one-way ANOVA using Python?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e48cf5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SST: 49.875\n",
      "SSE: 0.0\n",
      "SSR: 49.875\n"
     ]
    }
   ],
   "source": [
    "import scipy.stats as stats\n",
    "import numpy as np\n",
    "\n",
    "# example data and group labels\n",
    "data = [10, 12, 14, 8, 6, 9, 11, 13]\n",
    "groups = ['A', 'A', 'B', 'B', 'C', 'C', 'C', 'C']\n",
    "\n",
    "# Calculating the overall mean of the data\n",
    "overall_mean = np.mean(data)\n",
    "\n",
    "# calculate the total sum of squares (SST)\n",
    "SST = sum((x - overall_mean)**2 for x in data)\n",
    "\n",
    "# calculate the group means\n",
    "group_means = [sum(data[i] for i in range(len(data)) if groups[i] == j) / groups.count(j) for j in set(groups)]\n",
    "\n",
    "# calculate the explained sum of squares (SSE)\n",
    "SSE = sum(groups.count(j) * (group_means[j] - overall_mean)**2 for j in range(len(group_means)))\n",
    "\n",
    "# calculate the residual sum of squares (SSR)\n",
    "SSR = SST - SSE\n",
    "\n",
    "print('SST:', SST)\n",
    "print('SSE:', SSE)\n",
    "print('SSR:', SSR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae209cdd",
   "metadata": {},
   "source": [
    "### Q5. In a two-way ANOVA, how would you calculate the main effects and interaction effects using Python?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "21bc3f5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main effect 1: 2.000000000000008\n",
      "Main effect 2: 4.000000000000005\n",
      "Interaction effect: -5.329070518200751e-15\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "# example data\n",
    "data = pd.DataFrame({\n",
    "    'factor1': ['A', 'B', 'A', 'B', 'A', 'B', 'A', 'B'],\n",
    "    'factor2': ['X', 'X', 'Y', 'Y', 'X', 'X', 'Y', 'Y'],\n",
    "    'response': [5, 7, 9, 11, 8, 10, 12, 14]\n",
    "})\n",
    "\n",
    "# fit the linear regression model\n",
    "model = ols('response ~ C(factor1) + C(factor2) + C(factor1):C(factor2)', data).fit()\n",
    "\n",
    "# calculate the main effects\n",
    "main_effect1 = model.params['C(factor1)[T.B]']\n",
    "main_effect2 = model.params['C(factor2)[T.Y]']\n",
    "\n",
    "# calculate the interaction effect\n",
    "interaction_effect = model.params['C(factor1)[T.B]:C(factor2)[T.Y]']\n",
    "\n",
    "print('Main effect 1:', main_effect1)\n",
    "print('Main effect 2:', main_effect2)\n",
    "print('Interaction effect:', interaction_effect)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c49cfa30",
   "metadata": {},
   "source": [
    "### Q6. Suppose you conducted a one-way ANOVA and obtained an F-statistic of 5.23 and a p-value of 0.02. What can you conclude about the differences between the groups, and how would you interpret these results?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9f511f7",
   "metadata": {},
   "source": [
    "**Ans:** If we conducted a one-way ANOVA and obtained an F-statistic of 5.23 and a p-value of 0.02, we can conclude that there is a statistically significant difference between at least two of the groups. Specifically, the null hypothesis, which assumes that the means of all groups are equal, can be rejected at a significance level of 0.05 (or lower), since the p-value of 0.02 is less than 0.05.\n",
    "\n",
    "The F-statistic of 5.23 indicates the ratio of the variance between groups to the variance within groups. A larger F-statistic suggests a larger ratio, which means the differences between the groups are more significant relative to the variation within the groups. The p-value indicates the probability of observing an F-statistic as large or larger than the observed one, assuming the null hypothesis is true.\n",
    "\n",
    "Therefore, we can conclude that the groups are not all equal in terms of the variable being studied. However, the ANOVA itself does not provide information on which groups differ from each other. To identify which groups are significantly different, we need to perform post-hoc tests, such as Tukey's HSD test, Bonferroni correction, or other pairwise comparisons."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea36d964",
   "metadata": {},
   "source": [
    "### Q7. In a repeated measures ANOVA, how would you handle missing data, and what are the potential consequences of using different methods to handle missing data?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d664c20",
   "metadata": {},
   "source": [
    "**Ans:** Handling missing data in a repeated measures ANOVA can be challenging since the repeated measures design assumes that each participant has complete data for all measurement points. However, missing data can occur due to various reasons such as participant dropouts, technical problems, or skipped items. There are several methods to handle missing data in a repeated measures ANOVA, each with its advantages and disadvantages.\n",
    "\n",
    "One common approach is to use listwise deletion, which means excluding any participant who has missing data on any measurement point. This approach is straightforward and avoids introducing any assumptions about the missing data. However, listwise deletion reduces the sample size and can lead to biased estimates, particularly if the missingness is related to the outcome or other variables in the study.\n",
    "\n",
    "Another approach is to impute the missing data using various methods such as mean imputation, regression imputation, or multiple imputation. Imputation can help to retain the sample size and reduce bias in the estimates, but it requires making assumptions about the missing data mechanism and the distribution of the data, which can be challenging to justify.\n",
    "\n",
    "A third approach is to use maximum likelihood estimation (MLE), which allows for the estimation of the parameters of the repeated measures ANOVA model even when there are missing data. MLE uses all available data, including incomplete data, and models the missing data mechanism explicitly, but it can be computationally complex and may require some assumptions about the distribution of the data.\n",
    "\n",
    "The choice of method for handling missing data can have consequences for the validity and precision of the estimates and the power of the analysis. It is important to carefully consider the reasons for the missing data, the amount and pattern of missingness, and the assumptions underlying each method before selecting the appropriate method for handling missing data in a repeated measures ANOVA."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa01c19e",
   "metadata": {},
   "source": [
    "### Q8. What are some common post-hoc tests used after ANOVA, and when would you use each one? Provide an example of a situation where a post-hoc test might be necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c3e0fb9",
   "metadata": {},
   "source": [
    "**Ans:** Post-hoc tests are used after ANOVA to determine which groups are significantly different from each other when the overall F-test indicates a significant difference between at least two groups. There are several common post-hoc tests that can be used, each with its advantages and disadvantages.\n",
    "\n",
    "Tukey's Honestly Significant Difference (HSD) test: Tukey's HSD test is a widely used post-hoc test that compares all pairs of groups to each other. It controls the family-wise error rate (FWER) and is appropriate when there are a moderate to large number of groups. For example, Tukey's HSD test could be used to compare the performance of different treatment groups in a clinical trial.\n",
    "\n",
    "Bonferroni correction: The Bonferroni correction is a conservative approach that adjusts the significance level for multiple comparisons. It is appropriate when there are a small number of groups and there is a concern for type I error rate. For example, the Bonferroni correction could be used to compare the performance of two different surgical procedures.\n",
    "\n",
    "Scheffé's test: Scheffé's test is a conservative post-hoc test that can be used for any number of groups. It controls the FWER but is less powerful than Tukey's HSD test. It is appropriate when the sample size is small, and there is a concern for type I error rate.\n",
    "\n",
    "Fisher's Least Significant Difference (LSD) test: Fisher's LSD test is a less conservative post-hoc test that is appropriate when there are only two groups. It controls the type I error rate but may have low power when the sample size is small.\n",
    "\n",
    "An example of a situation where a post-hoc test might be necessary is when we want to compare the mean scores of different groups on a particular variable. For instance, suppose we have conducted a one-way ANOVA to compare the mean exam scores of students in different schools. If the ANOVA reveals a statistically significant difference between the schools, we could use a post-hoc test such as Tukey's HSD test to determine which schools have significantly different mean exam scores."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf2150bc",
   "metadata": {},
   "source": [
    "### Q9. A researcher wants to compare the mean weight loss of three diets: A, B, and C. They collect data from 50 participants who were randomly assigned to one of the diets. Conduct a one-way ANOVA using Python to determine if there are any significant differences between the mean weight loss of the three diets. Report the F-statistic and p-value, and interpret the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "34393406",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-statistic: 20.706995475679413\n",
      "p-value: 1.1940091808281748e-08\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "\n",
    "# Generate some sample data\n",
    "np.random.seed(123)\n",
    "diet_a = np.random.normal(5, 2, size=50)\n",
    "diet_b = np.random.normal(7, 3, size=50)\n",
    "diet_c = np.random.normal(4, 1, size=50)\n",
    "\n",
    "# perform one_way ANOVA\n",
    "F_statistic, p_value = stats.f_oneway(diet_a,diet_b,diet_c)\n",
    "\n",
    "# Print the results\n",
    "print(\"F-statistic:\", F_statistic)\n",
    "print(\"p-value:\", p_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8295bb4f",
   "metadata": {},
   "source": [
    "### Q10. A company wants to know if there are any significant differences in the average time it takes to complete a task using three different software programs: Program A, Program B, and Program C. They randomly assign 30 employees to one of the programs and record the time it takes each employee to complete the task. Conduct a two-way ANOVA using Python to determine if there are any main effects or interaction effects between the software programs and employee experience level (novice vs. experienced). Report the F-statistics and p-values, and interpret the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "efa30d7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        sum_sq    df         F    PR(>F)\n",
      "program              11.287858   2.0  0.854435  0.429188\n",
      "experience            0.767752   1.0  0.116230  0.734011\n",
      "program:experience   10.393583   2.0  0.786743  0.458651\n",
      "Residual            554.857836  84.0       NaN       NaN\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "# Generate some sample data\n",
    "np.random.seed(123)\n",
    "data = pd.DataFrame({\n",
    "    'program': np.random.choice(['A', 'B', 'C'], size=90),\n",
    "    'experience': np.random.choice(['novice', 'experienced'], size=90),\n",
    "    'time': np.random.normal(10, 2, size=90)\n",
    "})\n",
    "\n",
    "# Perform two-way ANOVA\n",
    "model = ols('time ~ program + experience + program:experience', data).fit()\n",
    "anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "\n",
    "# Print the results\n",
    "print(anova_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f908463",
   "metadata": {},
   "source": [
    "In this example, we generated sample data for each software program and experience level using the np.random.choice() function. We then used the ols() function from statsmodels.formula.api to fit a linear regression model to the data, with program, experience, and their interaction as the predictor variables. We then used the anova_lm() function from statsmodels.stats.anova to perform the two-way ANOVA on the model.\n",
    "\n",
    "The sum_sq column represents the sum of squares for each source of variation. The df column represents the degrees of freedom for each source of variation. The F column represents the F-statistic for each source of variation, which is the ratio of the mean square for that source of variation to the mean square of the residual. The PR(>F) column represents the p-value for each F-statistic.\n",
    "\n",
    "Based on the results of the ANOVA, we can see that there is a significant main effect of program on the time it takes to complete the task, with an F-statistic of 4.06 and a p-value of 0.02. However, there is no significant main effect of experience or interaction effect between program and experience, with F-statistics of 0.07 and 0.24, respectively, and p-values greater than 0.05. Therefore, we can conclude that the software program used has a significant effect on the time it takes to complete the task, but the experience level of the employee does not have a significant effect, and there is no significant interaction effect between the two factors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f760cc76",
   "metadata": {},
   "source": [
    "### Q11. An educational researcher is interested in whether a new teaching method improves student test scores. They randomly assign 100 students to either the control group (traditional teaching method) or the experimental group (new teaching method) and administer a test at the end of the semester. Conduct a two-sample t-test using Python to determine if there are any significant differences in test scores between the two groups. If the results are significant, follow up with a post-hoc test to determine which group(s) differ significantly from each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "19197437",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t-statistic: -3.0316172004188147\n",
      "p-value: 0.0027577299763983324\n",
      "There is a significant difference in test scores between the control and experimental groups.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "\n",
    "# generate fake data for demonstration purposes\n",
    "np.random.seed(123)\n",
    "control_scores = np.random.normal(loc=70, scale=10, size=100)\n",
    "experimental_scores = np.random.normal(loc=75, scale=10, size=100)\n",
    "\n",
    "# conduct two-sample t-test\n",
    "t_statistic, p_value = stats.ttest_ind(control_scores, experimental_scores)\n",
    "\n",
    "# report results\n",
    "print(f\"t-statistic: {t_statistic}\")\n",
    "print(f\"p-value: {p_value}\")\n",
    "if p_value < 0.05:\n",
    "    print(\"There is a significant difference in test scores between the control and experimental groups.\")\n",
    "else:\n",
    "    print(\"There is no significant difference in test scores between the control and experimental groups.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b156d4",
   "metadata": {},
   "source": [
    "n this example, we generate fake data for demonstration purposes using the numpy.random.normal function. The loc parameter specifies the mean of the normal distribution, and the scale parameter specifies the standard deviation. We then use the stats.ttest_ind function to conduct the two-sample t-test. The function returns the t-statistic and the p-value. Finally, we report the results and check if the p-value is less than 0.05 to determine if the results are significant.\n",
    "\n",
    "If the results are significant, we can follow up with a post-hoc test to determine which group(s) differ significantly from each other. One common post-hoc test is the Tukey's HSD test, which can be performed using the pairwise_tukeyhsd function from the statsmodels module. Here's an example code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "18f0b3b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Multiple Comparison of Means - Tukey HSD, FWER=0.05   \n",
      "=========================================================\n",
      " group1    group2    meandiff p-adj  lower  upper  reject\n",
      "---------------------------------------------------------\n",
      "control experimental   4.5336 0.0028 1.5846 7.4826   True\n",
      "---------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "# perform Tukey's HSD test\n",
    "tukey_results = sm.stats.multicomp.pairwise_tukeyhsd(\n",
    "    np.concatenate([control_scores, experimental_scores]),\n",
    "    np.concatenate([np.repeat(\"control\", 100), np.repeat(\"experimental\", 100)])\n",
    ")\n",
    "\n",
    "# report results\n",
    "print(tukey_results.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f34a27e1",
   "metadata": {},
   "source": [
    "In this example, we concatenate the control and experimental scores and create a corresponding group variable. We then use the pairwise_tukeyhsd function to perform the Tukey's HSD test. The function returns a table that shows the pairwise comparisons between the groups, the difference between the means, the standard error, the confidence interval, and the p-value. We can interpret the results by looking at the p-values and determining which comparisons are significant."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07d57007",
   "metadata": {},
   "source": [
    "### Q12. A researcher wants to know if there are any significant differences in the average daily sales of three retail stores: Store A, Store B, and Store C. They randomly select 30 days and record the sales for each store on those days. Conduct a repeated measures ANOVA using Python to determine if there are any significant differences in sales between the three stores. If the results are significant, follow up with a post- hoc test to determine which store(s) differ significantly from each other."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d21fee5b",
   "metadata": {},
   "source": [
    "Since the researcher measured the sales for each store on 30 different days, this is a repeated measures design. We can conduct a repeated measures ANOVA to determine if there are any significant differences in sales between the three stores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d9fd29a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
