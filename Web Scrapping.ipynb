{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48057327",
   "metadata": {},
   "source": [
    "## Web Scrapping : Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a86c5078",
   "metadata": {},
   "source": [
    "#### Q1. What is Web Scraping? Why is it Used? Give three areas where Web Scraping is used to get data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a73d7b9e",
   "metadata": {},
   "source": [
    "**Ans:** \n",
    "Web scraping is the process of extracting data from websites using automated tools or scripts. It involves accessing web pages, parsing their content, and retrieving the desired information for analysis, research, or other purposes. \n",
    "\n",
    "Web scraping is used for various reasons:\n",
    "\n",
    "1. Data Aggregation and Analysis\n",
    "\n",
    "2. Market Research and Competitive Intelligence\n",
    "\n",
    "3. Content Monitoring and Sentiment Analysis\n",
    "\n",
    "4. Academic Research and Data Collection\n",
    "\n",
    "5. Lead Generation and Sales Intelligence\n",
    "\n",
    "Here are three common areas where web scraping is widely used to gather data:\n",
    "\n",
    "1. E-commerce and Price Comparison\n",
    "2. Real Estate and Property Listings\n",
    "3. Financial and Stock Market Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34e3b353",
   "metadata": {},
   "source": [
    "#### Q2. What are the different methods used for Web Scraping?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd4fd47",
   "metadata": {},
   "source": [
    "**Ans:**\n",
    "\n",
    "1. Parsing HTML/XML\n",
    "\n",
    "2. Using APIs\n",
    "\n",
    "3. Automated Web Browsing\n",
    "\n",
    "4. HTTP Requests and Web Crawling\n",
    "\n",
    "5. Machine Learning Techniques\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0c2e857",
   "metadata": {},
   "source": [
    "#### Q3. What is Beautiful Soup? Why is it used?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42adbea6",
   "metadata": {},
   "source": [
    "**Ans:**\n",
    "\n",
    "Beautiful Soup is a popular Python library used for web scraping and parsing HTML or XML documents. It provides a convenient and efficient way to extract data from web pages by navigating and manipulating the document's structure.\n",
    "\n",
    "Beautiful Soup is used for web scraping and parsing HTML or XML documents. It simplifies the extraction of data from web pages by providing easy navigation, powerful search capabilities, and efficient data extraction methods. It is widely used because it makes web scraping tasks in Python more convenient, efficient, and adaptable to different website structures and formats."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de8e2720",
   "metadata": {},
   "source": [
    "#### Q4. Why is flask used in this Web Scraping project?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74295198",
   "metadata": {},
   "source": [
    "**Ans:**\n",
    "Flask is a popular web framework in Python that is commonly used in web scraping projects for several reasons:\n",
    "\n",
    "1. Web Application Development: Flask provides a lightweight and flexible framework for building web applications. When combined with web scraping, Flask allows you to create a user-friendly interface to display the scraped data, perform additional data processing or analysis, and provide interactivity to users.\n",
    "\n",
    "2. Routing and Request Handling: Flask's routing capabilities enable you to define endpoints and handle HTTP requests efficiently. In a web scraping project, you can define routes for different pages or actions, such as initiating a scrape, displaying scraped data, or handling user interactions.\n",
    "\n",
    "3. Templating Engine: Flask comes with a built-in templating engine, such as Jinja2, which allows you to easily render dynamic HTML templates. This is useful for presenting scraped data in a visually appealing format or customizing the display based on user preferences.\n",
    "\n",
    "4. Data Persistence and Storage: Flask integrates well with various databases, such as SQLite or MySQL, enabling you to store and manage the scraped data persistently. You can save the scraped data into a database or file system, retrieve it when needed, and perform advanced queries or analytics on the collected data.\n",
    "\n",
    "5. Deployment and Scalability: Flask provides a straightforward process for deploying web applications, making it easier to share your scraping project with others or deploy it to production. Additionally, Flask's lightweight nature allows for easy scalability and integration with other tools or services for handling larger-scale web scraping tasks.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7feb493c",
   "metadata": {},
   "source": [
    "#### Q5. Write the names of AWS services used in this project. Also, explain the use of each service."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "214972dd",
   "metadata": {},
   "source": [
    "**Ans:** The AWS services used in this project are :\n",
    "\n",
    "**1. AWS Code Pipeline:** CodePipeline is primarily used for setting up continuous integration and continuous delivery (CI/CD) workflows. It helps automate the process of building, testing, and deploying applications. With CodePipeline, you can define a series of stages, each representing a step in your software release process, such as source code retrieval, building, testing, and deployment. CodePipeline integrates with various AWS services and third-party tools to enable seamless orchestration of the entire release process. It provides a visual interface for monitoring and managing the status of your pipeline, facilitating faster and more reliable software delivery.\n",
    "\n",
    "**2. AWS Elastic Beanstalk:** Elastic Beanstalk is a fully managed platform-as-a-service (PaaS) offering from AWS. Its primary use is simplifying the deployment and management of applications. With Elastic Beanstalk, you can easily deploy web applications written in various programming languages, such as Java, .NET, Node.js, Python, and more. It abstracts away the complexities of infrastructure provisioning, load balancing, auto-scaling, and application health monitoring. Elastic Beanstalk handles these aspects automatically, allowing developers to focus on writing code and deploying applications quickly. It provides an environment where you can easily upload your application code and let Elastic Beanstalk handle the deployment and management aspects behind the scenes."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
